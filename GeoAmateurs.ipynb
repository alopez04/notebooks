{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So What is a Jupyter Notebook?\n",
    "_The Jupyter Notebook is a web application for interactive data science and scientific computing. It allows users to author documents that combine live-code with narrative text, equations, images, video and visualizations._\n",
    "\n",
    "source: https://jupyter.readthedocs.org/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#So... what is it? -- It's Python (or other language) in your web browser. \n",
    "Jupyter is the evolution of the IPython Notebook. \n",
    "\n",
    "## Advantages\n",
    "- **Instant Gratification with Data Discovery**\n",
    "    - _Who wants/has time to sift through JPGs? Or organize open windows to view charts side-by-side?_\n",
    "- **Story Telling with Data**\n",
    "    - _Narate your graphs, maps, visualizations, equations, etc_\n",
    "- **Multiple Language Intergration**\n",
    "    - _Python missing a key statistical method (becoming less likely, Dan)? Swith to R or Matlab or Julia or any other 48 someting supported languages_\n",
    "- **It's a server, meaning you can connect to remote servers**\n",
    "    - _If data is stored on external server, keep it there and still work locally!_\n",
    "- **Packaged with Anaconda - quick and easy to get started**\n",
    "    - _Great way for beginners to get started - think, no complicated IDE and just enough interaction to be more useful than a text editor_\n",
    "- **Collaboration**\n",
    "    - _Use with Github_\n",
    "        - _If data is small enough, store in Git; if not, store in a database or other cloud option to make collaboration even easier_\n",
    "    - _Standardize data visualizations of model outputs_\n",
    "- **Reproducable Research**\n",
    "    - _Give someone your Notebook and data and they can instantly reproduce your results_\n",
    "    - _Becoming standard in the scientific community_\n",
    "\n",
    "## Disadvantages\n",
    "- **Missing my IDE**\n",
    "    - _Can't say that I'd fully replace my IDE with it..._\n",
    "    - _Debug is nice to have_\n",
    "    - _Code inspection can be very helpful in complex code_\n",
    "    \n",
    "# How is NREL Using Jupyter?\n",
    "- Collaborative reporting tool for agent-based diffusion models and electricity capacity expansion models\n",
    "- Model/data diagnostics for solar resource assessment - direct link to > 50 TB of data on NRELs High Performance Computer\n",
    "- Rewewable energy supply curve regional and cost breakdown visualizations\n",
    "- Other random acts of visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enough Talk, Let's Step Through an Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solar Energy Potential for Front Range Cities\n",
    "How much energy can Colorado cities harness from the sun? This quick demo will explore and try to answer this question using basic GIS technology with some energy modeling software. \n",
    "\n",
    "**NOTICE:** Don't get caught up in the solar domain jargin, concentrate on the flow of the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do some imports...\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import psycopg2\n",
    "import json\n",
    "import urllib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import System Advisor Model SSC...\n",
    "import site\n",
    "site.addsitedir('/Users/alopez/Applications/sam-sdk-2015-6-30-r2/languages/python')\n",
    "import sscapi\n",
    "ssc = sscapi.PySSC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create connection to postgres database\n",
    "conn = psycopg2.connect('dbname=alopez user=alopez host=localhost password=alopez')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Potential Solar Capacity (MW) for Front Range Cities?\n",
    "What is the solar potential for Colorado cities? We can use a grid that has available land for solar development (technical potential) and intersect with city boundaries to find out. Nothing special here, just some basic GIS.\n",
    "\n",
    "__Data Needs:__\n",
    " - Land Available for Solar Development\n",
    " - City Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# perform spatial intersection between urban areas and solar potential grid\n",
    "sql = '''SELECT a.name, SUM(b.pv_tech_pot) * 35 AS \"MW\"\n",
    "         FROM urban a\n",
    "         INNER JOIN grid b ON ST_Intersects(a.the_geom_4326, b.the_geom_4326)\n",
    "         WHERE a.name IN ('Denver--Aurora', 'Fort Collins', 'Pueblo', 'Colorado Springs', 'Greeley', 'Boulder')\n",
    "         GROUP BY a.name;'''\n",
    "df_cap = pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# graph results\n",
    "ax = df_cap.plot(kind='bar', figsize=(16,5), fontsize=15, \n",
    "        title='Front Range Solar Electricity Capacity Potential {s} MW'.format(s=df_cap['MW'].sum()))\n",
    "_ = ax.set_xticklabels(df_cap['name'], rotation=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's the Potential Generation (TWh) of Colorado Cities?\n",
    "Let's pick one one solar resource profile for each Colorado city (solar resource has high spatial autocorrelation, besides.. this is just a demo!) and estimate how much electric generation we could get. \n",
    "\n",
    "**Data Needs:**\n",
    "- Hourly solar and meteorological profiles for each city\n",
    "- Electric capacity potential for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hello SAM. SAM function for estimating solar energy\n",
    "def sam_run(df, lon, lat):\n",
    "    # resource inputs\n",
    "    wfd = ssc.data_create()\n",
    "    ssc.data_set_number(wfd, 'lat', lat)\n",
    "    ssc.data_set_number(wfd, 'lon', lon)\n",
    "    ssc.data_set_number(wfd, 'tz', -7)\n",
    "    ssc.data_set_number(wfd, 'elev', 1800)\n",
    "    ssc.data_set_array(wfd, 'year', df.index.year)\n",
    "    ssc.data_set_array(wfd, 'month', df.index.month)\n",
    "    ssc.data_set_array(wfd, 'day', df.index.day)\n",
    "    ssc.data_set_array(wfd, 'hour', df.index.hour)\n",
    "    ssc.data_set_array(wfd, 'minute', df.index.minute)\n",
    "    ssc.data_set_array(wfd, 'dn', df['DNI'])\n",
    "    ssc.data_set_array(wfd, 'df', df['DHI'])\n",
    "    ssc.data_set_array(wfd, 'wspd', df['Wind Speed'])\n",
    "    ssc.data_set_array(wfd, 'tdry', df['Temperature'])\n",
    "\n",
    "    dat = ssc.data_create()\n",
    "    ssc.data_set_table(dat, 'solar_resource_data', wfd)\n",
    "    ssc.data_free(wfd)\n",
    "\n",
    "    # System Config\n",
    "    ssc.data_set_number(dat, 'system_capacity', 1000)\n",
    "    ssc.data_set_number(dat, 'dc_ac_ratio', 1.1)\n",
    "    ssc.data_set_number(dat, 'tilt', 25)\n",
    "    ssc.data_set_number(dat, 'azimuth', 180)\n",
    "    ssc.data_set_number(dat, 'inv_eff', 96)\n",
    "    ssc.data_set_number(dat, 'losses', 14.0757)\n",
    "    ssc.data_set_number(dat, 'array_type', 0)\n",
    "    ssc.data_set_number(dat, 'gcr', 0.4)\n",
    "    ssc.data_set_number(dat, 'adjust:constant', 0)\n",
    "\n",
    "    # execute and stuff results back into df\n",
    "    mod = ssc.module_create('pvwattsv5')\n",
    "    ssc.module_exec(mod, dat)\n",
    "    generation = np.array(ssc.data_get_array(dat, 'gen'))\n",
    "    \n",
    "    # free the memory\n",
    "    ssc.data_free(dat)\n",
    "    ssc.module_free(mod)\n",
    "    \n",
    "    return generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select One Location for Each Urban Area\n",
    "sql = '''SELECT DISTINCT ON (a.name) a.name, ST_X(ST_Centroid(a.the_geom_4326)) AS lon, ST_Y(ST_Centroid(a.the_geom_4326)) AS lat \n",
    "         FROM urban a\n",
    "         INNER JOIN grid b ON ST_Intersects(a.the_geom_4326, b.the_geom_4326)\n",
    "         WHERE a.name IN ('Denver--Aurora', 'Fort Collins', 'Pueblo', 'Colorado Springs', 'Greeley', 'Boulder')'''\n",
    "results = pd.read_sql(sql, conn)\n",
    "\n",
    "# Store Results from SAM in Here\n",
    "df_gen = pd.DataFrame(columns=['name', 'kWh'])\n",
    "year = 2005\n",
    "for i, row in results.iterrows():\n",
    "    # API Call (well would be..) to Download Solar Resource Data\n",
    "    wf = pd.read_csv('./data/{lon}_{lat}_{year}.csv'.format(lon=row['lon'], lat=row['lat'], year=year))\n",
    "    \n",
    "    # Set the time index in the pandas dataframe\n",
    "    wf = wf.set_index(pd.date_range('1/1/{yr}'.format(yr=year), tz='US/Mountain', freq='1h', periods=8760))\n",
    "\n",
    "    # Execute SAM Model Run\n",
    "    gen = sam_run(wf, row['lon'], row['lat'])\n",
    "    \n",
    "    #Gather Results\n",
    "    df_gen = pd.concat([df_gen, pd.DataFrame({'name': [row['name']], 'kWh': [gen.sum()]})])\n",
    "\n",
    "# determine the system performance\n",
    "df_gen['capacity factor'] = df_gen['kWh'] / (8760 * 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Last Step. Join Capacity Factor Data with Capacity to Determine Generation\n",
    "df = pd.merge(df_cap, df_gen, on='name')\n",
    "df['Total TWh'] = (df['MW'] * 8760 * df['capacity factor']) / 1000000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# graph results\n",
    "ax = df[['name', 'Total TWh']].plot(kind='bar', figsize=(16,5), fontsize=15, \n",
    "        title='Front Range Solar Electricity Generation {g} TWh'.format(g=round(df['Total TWh'].sum())))\n",
    "_ = ax.set_xticklabels(df['name'].values, rotation=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So How Does this Compare to Current Energy Use?\n",
    "Let's grab some data from the Energy Information Administration using their web API. Web API's are your friend. They take the storage component of using data out of your wheelhouse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://api.eia.gov/series/?api_key=78C213EA8D7ACC72A0296C69B88EC160&series_id=SEDS.ESRCP.CO.A'\n",
    "j = urllib2.urlopen(url).read()\n",
    "eia = np.array(json.loads(j[3:])['series'][0]['data'])\n",
    "eia = pd.DataFrame({'Historic Consumption (TWh)' : eia[:, 1].astype(np.float) / 1000., \n",
    "                    'Potential Generation (TWh)': df['Total TWh'].sum()}, index=eia[:, 0]).sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = eia.plot(figsize=(17, 5), title='Colorado Residential Energy Consumption')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well That Looks Like Good News. We have Enough Energy to Last a Long Time. \n",
    "But wait... that was only one year of data, plainly speaking, the sun don't shine the same year-after-year, does it? \n",
    "\n",
    "Nope. So let's take a closer look at Denver. What's the interannual variability of solar and what does this mean for Denver's energy potential? We can use a measure called p50, which gives us a generation number with a 50% probability of happening every year. Since solar is non-normal, we determine probabilities using an empirical cumulative distribution function (ECDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# iterate over each year, get data, run in SAM\n",
    "denver = results[results['name'] == 'Denver--Aurora']\n",
    "\n",
    "pN = pd.DataFrame(columns=['year', 'kWh'])\n",
    "for year in range(2005, 2013):\n",
    "    # read weather data\n",
    "    wf = pd.read_csv('./data/{lon}_{lat}_{year}.csv'.format(lat=denver['lat'].iloc[0], lon=denver['lon'].iloc[0], year=year))\n",
    "    \n",
    "    # Set the time index in the pandas dataframe\n",
    "    wf = wf.set_index(pd.date_range('1/1/{yr}'.format(yr=year), tz='US/Mountain', freq='1h', periods=8760))\n",
    "\n",
    "    # Execute SAM Model Run\n",
    "    gen = sam_run(wf, denver['lon'], denver['lat'])\n",
    "    \n",
    "    #Gather Results\n",
    "    pN = pd.concat([pN, pd.DataFrame({'year': [year], 'kWh': [gen.sum()]})])\n",
    "\n",
    "# determine the system performance by year\n",
    "pN['capacity factor'] = pN['kWh'] / (8760 * 1000) \n",
    "\n",
    "# calculate the total TWh in the City for each year\n",
    "pN['Total TWh'] = (df[df['name'] == 'Denver--Aurora']['MW'].iloc[0] * 8760 * pN['capacity factor']) / 1000000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pN = pN[['Total TWh', 'year']]\n",
    "pN = pN.set_index('year')\n",
    "_ = pN.plot(figsize=(16,5), title='Inter-Annual Solar Generation Variability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate p50\n",
    "import statsmodels.api as sm\n",
    "ecdf = sm.distributions.ECDF(pN['Total TWh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ecdf = pd.DataFrame(ecdf.x, index=ecdf.y)\n",
    "p50 = df_ecdf[df_ecdf.index == 0.5].iloc[0].values\n",
    "ax = df_ecdf.plot(figsize=(16, 5), legend=False, title='p50 - Denver Colorado')\n",
    "ax.set_xticks(df_ecdf.index)\n",
    "plt.axvline(0.5, color='k', ls='--')\n",
    "plt.axhline(p50, color='k', ls='--')\n",
    "plt.text(0.51, p50+0.05, 'Denver p50: {v} (TWh)'.format(v=round(p50, 2)), fontsize=15)\n",
    "hc = eia.iloc[-1]['Historic Consumption (TWh)']\n",
    "plt.axhline(hc)\n",
    "plt.text(0, hc + 0.05, 'Colorado 2013 Consumption: {y} (TWh)'.format(y=round(hc, 2)), fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Need Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML('<iframe width=\"100%\" height=\"520\" frameborder=\"0\" src=\"https://alopez.cartodb.com/viz/a2d2f138-19f6-11e5-b8b3-0e0c41326911/embed_map\" allowfullscreen webkitallowfullscreen mozallowfullscreen oallowfullscreen msallowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
